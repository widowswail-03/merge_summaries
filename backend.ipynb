{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0088c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155c7fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1f7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File not found - [Errno 2] No such file or directory: 'Analyst1.txt'\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "def parse_report_file(filename):\n",
    "    \"\"\"Parse a text file into a list of report items.\"\"\"\n",
    "    reports = []\n",
    "    current_item = {}\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line or line == \"---\":\n",
    "                if current_item and \"title\" in current_item and \"summary\" in current_item and \"insight\" in current_item:\n",
    "                    reports.append(current_item)\n",
    "                    current_item = {}\n",
    "                continue\n",
    "            if line.startswith(\"Title:\"):\n",
    "                current_item[\"title\"] = line.replace(\"Title:\", \"\").strip()\n",
    "            elif line.startswith(\"Summary:\"):\n",
    "                current_item[\"summary\"] = line.replace(\"Summary:\", \"\").strip()\n",
    "            elif line.startswith(\"Insight:\"):\n",
    "                current_item[\"insight\"] = line.replace(\"Insight:\", \"\").strip()\n",
    "            elif line.startswith(\"Timestamp:\"):\n",
    "                current_item[\"timestamp\"] = line.replace(\"Timestamp:\", \"\").strip()\n",
    "    if current_item and \"title\" in current_item and \"summary\" in current_item and \"insight\" in current_item:\n",
    "        reports.append(current_item)\n",
    "    return reports\n",
    "\n",
    "def compute_similarity(text1, text2):\n",
    "    \"\"\"Calculate semantic similarity between two texts using spaCy.\"\"\"\n",
    "    doc1 = nlp(text1)\n",
    "    doc2 = nlp(text2)\n",
    "    return doc1.similarity(doc2)\n",
    "\n",
    "def extract_tags(summary):\n",
    "    \"\"\"Extract tags from summary using keyword mapping.\"\"\"\n",
    "    doc = nlp(summary)\n",
    "    tags = []\n",
    "    keyword_map = {\n",
    "        \"Tech\": [\"tech\", \"ai\", \"technology\", \"stocks\"],\n",
    "        \"Economy\": [\"fed\", \"rate\", \"inflation\", \"economy\"],\n",
    "        \"Markets\": [\"stocks\", \"market\", \"sector\"],\n",
    "        \"Energy\": [\"oil\", \"energy\"]\n",
    "    }\n",
    "    for token in doc:\n",
    "        for tag, keywords in keyword_map.items():\n",
    "            if token.lower_ in keywords and tag not in tags:\n",
    "                tags.append(tag)\n",
    "    return tags if tags else [\"General\"]\n",
    "\n",
    "def extract_numbers(summary):\n",
    "    \"\"\"Extract numerical entities (e.g., percentages) from summary.\"\"\"\n",
    "    doc = nlp(summary)\n",
    "    numbers = [ent.text for ent in doc.ents if ent.label_ in [\"PERCENT\", \"CARDINAL\", \"MONEY\"]]\n",
    "    return numbers\n",
    "\n",
    "def resolve_conflict(summary_a, summary_b, item_a, item_b):\n",
    "    \"\"\"Resolve conflicting summaries.\"\"\"\n",
    "    numbers_a = extract_numbers(summary_a)\n",
    "    numbers_b = extract_numbers(summary_b)\n",
    "    \n",
    "\n",
    "    if numbers_a != numbers_b:\n",
    "        timestamp_a = item_a.get(\"timestamp\")\n",
    "        timestamp_b = item_b.get(\"timestamp\")\n",
    "        if timestamp_a and timestamp_b:\n",
    "            try:\n",
    "                time_a = datetime.strptime(timestamp_a, \"%Y-%m-%d %H:%M:%S\")\n",
    "                time_b = datetime.strptime(timestamp_b, \"%Y-%m-%d %H:%M:%S\")\n",
    "                return summary_a if time_a > time_b else summary_b, None\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        if any(\"%\" in num for num in numbers_a + numbers_b):\n",
    "            numbers = [num for num in numbers_a + numbers_b if \"%\" in num]\n",
    "            if numbers:\n",
    "                min_num = min(float(num.rstrip(\"%\")) for num in numbers)\n",
    "                max_num = max(float(num.rstrip(\"%\")) for num in numbers)\n",
    "                merged_summary = summary_a.replace(numbers_a[0], f\"{min_num}-{max_num}%\") if numbers_a else summary_b\n",
    "                return merged_summary, None\n",
    "\n",
    "        return f\"{summary_a} (Analyst A); {summary_b} (Analyst B)\", \"Conflicting data detected, review required.\"\n",
    "    \n",
    "   \n",
    "    return summary_a if len(summary_a) > len(summary_b) else summary_b, None\n",
    "\n",
    "def deduplicate_reports(report_a, report_b, similarity_threshold=0.8):\n",
    "    \"\"\"Deduplicate reports and merge insights with conflict resolution.\"\"\"\n",
    "    merged_reports = []\n",
    "    used_indices_b = set()\n",
    "\n",
    "    for item_a in report_a:\n",
    "        matched = False\n",
    "        for i, item_b in enumerate(report_b):\n",
    "            if i in used_indices_b:\n",
    "                continue\n",
    "            if \"title\" not in item_a or \"title\" not in item_b:\n",
    "                continue  \n",
    "            similarity = compute_similarity(item_a[\"title\"], item_b[\"title\"])\n",
    "            if similarity > similarity_threshold:\n",
    "                \n",
    "                merged_summary, conflict_note = resolve_conflict(item_a[\"summary\"], item_b[\"summary\"], item_a, item_b)\n",
    "                \n",
    "                merged_item = {\n",
    "                    \"id\": len(merged_reports) + 1,\n",
    "                    \"title\": item_a[\"title\"],\n",
    "                    \"summary\": merged_summary,\n",
    "                    \"tags\": list(set(extract_tags(item_a[\"summary\"]) + extract_tags(item_b[\"summary\"]))),\n",
    "                    \"analysts\": [\n",
    "                        {\"name\": \"Analyst A\", \"insight\": item_a[\"insight\"]},\n",
    "                        {\"name\": \"Analyst B\", \"insight\": item_b[\"insight\"]}\n",
    "                    ]\n",
    "                }\n",
    "                if conflict_note:\n",
    "                    merged_item[\"conflict_note\"] = conflict_note\n",
    "                merged_reports.append(merged_item)\n",
    "                used_indices_b.add(i)\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            \n",
    "            merged_reports.append({\n",
    "                \"id\": len(merged_reports) + 1,\n",
    "                \"title\": item_a[\"title\"],\n",
    "                \"summary\": item_a[\"summary\"],\n",
    "                \"tags\": extract_tags(item_a[\"summary\"]),\n",
    "                \"analysts\": [{\"name\": \"Analyst A\", \"insight\": item_a[\"insight\"]}]\n",
    "            })\n",
    "\n",
    "    \n",
    "    for i, item_b in enumerate(report_b):\n",
    "        if i not in used_indices_b:\n",
    "            merged_reports.append({\n",
    "                \"id\": len(merged_reports) + 1,\n",
    "                \"title\": item_b[\"title\"],\n",
    "                \"summary\": item_b[\"summary\"],\n",
    "                \"tags\": extract_tags(item_b[\"summary\"]),\n",
    "                \"analysts\": [{\"name\": \"Analyst B\", \"insight\": item_b[\"insight\"]}]\n",
    "            })\n",
    "\n",
    "    return merged_reports\n",
    "\n",
    "def save_to_json(data, filename=\"reports.json\"):\n",
    "    \"\"\"Save merged reports to JSON.\"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "try:\n",
    "    report_a = parse_report_file(\"Analyst1.txt\")\n",
    "    report_b = parse_report_file(\"Analyst2.txt\")\n",
    "    merged_data = deduplicate_reports(report_a, report_b)\n",
    "    save_to_json(merged_data)\n",
    "    print(\"Successfully generated reports.json\")\n",
    "    print(json.dumps(merged_data, indent=2))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File not found - {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error processing reports: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae38078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
